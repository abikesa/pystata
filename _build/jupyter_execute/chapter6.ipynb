{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Translation\n",
    "\n",
    "Sure, I'll break down the Stata script into smaller code blocks with notes so you can run them separately in a Jupyter Notebook with the Stata kernel.\n",
    "\n",
    "### Block 1: Setup and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Close any existing log files\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Block 2: Define Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables for the repository URL and local directory path\n",
    "repo = \"https://github.com/muzaale/forum/raw/main/\"\n",
    "dir = \"~/documents/melody/local\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Block 3: Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Block 4: Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /Users/apollo/documents/melody/local/esrdRisk_t02tT.csv\n",
      "Dataset could not be loaded.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Open a new log file to record the output\n",
    "logging.basicConfig(filename='jamascript.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Log the start of the logging process\n",
    "logging.info('Starting log file')\n",
    "\n",
    "# Define the local directory and file name\n",
    "local_dir = os.path.expanduser(\"~/documents/melody/local\")\n",
    "file_name = \"esrdRisk_t02tT.csv\"\n",
    "file_path = os.path.join(local_dir, file_name)\n",
    "\n",
    "# Check if the file exists locally\n",
    "if os.path.isfile(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        logging.info('Dataset loaded successfully from local file')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load dataset from local file: {e}\")\n",
    "        print(f\"Failed to load dataset from local file: {e}\")\n",
    "        data = None\n",
    "else:\n",
    "    logging.error(f\"File not found: {file_path}\")\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    data = None\n",
    "\n",
    "if data is not None:\n",
    "    # Display the distribution of the 'donor' variable\n",
    "    donor_distribution = data['donor'].value_counts()\n",
    "    print(\"Distribution of 'donor' variable:\")\n",
    "    print(donor_distribution)\n",
    "\n",
    "    # Describe the 'rSMGJcEdF_d' variable\n",
    "    codebook = data['rSMGJcEdF_d'].describe()\n",
    "    print(\"\\nCodebook for 'rSMGJcEdF_d' variable:\")\n",
    "    print(codebook)\n",
    "\n",
    "    # Generate a new variable 'entry' based on the 'rSMGJcEdF_t0' variable\n",
    "    data['entry'] = data['rSMGJcEdF_t0']\n",
    "\n",
    "    # Logging the creation of the new variable\n",
    "    logging.info(\"New variable 'entry' created based on 'rSMGJcEdF_t0'\")\n",
    "else:\n",
    "    print(\"Dataset could not be loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Block 5: Data Cleaning and Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is messing up the dataset\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Assuming 'data' is the DataFrame loaded previously\n",
    "\n",
    "# Ensure the date columns are in datetime format\n",
    "data['rSMGJcEdF_tT'] = pd.to_datetime(data['rSMGJcEdF_tT'], format='%d%b%Y', errors='coerce')\n",
    "data['entry'] = pd.to_datetime(data['entry'], format='%d%b%Y', errors='coerce')\n",
    "\n",
    "# Define the critical dates\n",
    "date_2011 = pd.to_datetime('2011-12-31')\n",
    "date_1994 = pd.to_datetime('1994-01-01')\n",
    "\n",
    "# Log the start of the adjustment process\n",
    "logging.info(\"Starting the adjustment process for linkage dates\")\n",
    "\n",
    "# Linkage for donors after 2011 is untrustworthy\n",
    "data.loc[(data['rSMGJcEdF_tT'] > date_2011) & (data['donor'] == 1), 'rSMGJcEdF_d'] = 0\n",
    "data.loc[(data['rSMGJcEdF_tT'] > date_2011) & (data['donor'] == 1), 'rSMGJcEdF_tT'] = date_2011\n",
    "\n",
    "# Linkage before 1994 is untrustworthy\n",
    "data.loc[(data['entry'] < date_1994) & (data['rSMGJcEdF_tT'] > date_1994) & (data['donor'] == 1), 'entry'] = date_1994\n",
    "\n",
    "# Log the completion of the replacement process\n",
    "logging.info(\"Linkage for dates after 2011 and before 1994 adjusted successfully\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Block 6: Mortality Analysis Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming 'data' is already the DataFrame loaded previously\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Set the event indicator based on 'Died'\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrSMGJcEdF_d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDied\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure date columns are in datetime format\u001b[39;00m\n\u001b[1;32m     11\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrSMGJcEdF_tT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrSMGJcEdF_tT\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data' is already the DataFrame loaded previously\n",
    "\n",
    "# Set the event indicator based on 'Died'\n",
    "data['event'] = (data['rSMGJcEdF_d'] == 'Died').astype(int)\n",
    "\n",
    "# Ensure date columns are in datetime format\n",
    "data['rSMGJcEdF_tT'] = pd.to_datetime(data['rSMGJcEdF_tT'], errors='coerce')\n",
    "data['rSMGJcEdF_t0'] = pd.to_datetime(data['rSMGJcEdF_t0'], errors='coerce')\n",
    "data['entry'] = data['rSMGJcEdF_t0']  # Use _t0 as entry\n",
    "\n",
    "# Calculate the duration from origin to the event or censoring in years\n",
    "data['duration'] = (data['rSMGJcEdF_tT'] - data['rSMGJcEdF_t0']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    "\n",
    "# Calculate the entry duration\n",
    "data['entry_duration'] = (data['entry'] - data['rSMGJcEdF_t0']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    "data['entry_duration'] = data['entry_duration'].fillna(0)  # Ensure non-donor entries are set to 0\n",
    "\n",
    "# Ensure all durations are non-negative and valid\n",
    "data = data[(data['duration'] >= 0) & (data['entry_duration'] >= 0)]\n",
    "\n",
    "# Initialize the KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# Plot setup\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Unique donor values\n",
    "donor_values = data['donor'].unique()\n",
    "\n",
    "# Colors for each donor type\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "# Overlay plots for different donor values\n",
    "for donor, color in zip(donor_values, colors):\n",
    "    kmf.fit(durations=data[data['donor'] == donor]['duration'],\n",
    "            event_observed=data[data['donor'] == donor]['event'],\n",
    "            entry=data[data['donor'] == donor]['entry_duration'],\n",
    "            label=donor)\n",
    "    ax = kmf.plot_cumulative_density(ci_show=False, color=color)\n",
    "\n",
    "# Cut off the plot at 15 years\n",
    "plt.xlim(0, 15)\n",
    "\n",
    "# Convert y-axis to percentage\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Time (years)\")\n",
    "plt.ylabel(\"Failure Probability (%)\")\n",
    "plt.title(\"Failure Function Plot (Cumulative Density) by Donor Type\")\n",
    "plt.legend(title=\"Donor Type\")\n",
    "\n",
    "# Optional: Display the plot (depends on your environment)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Block 7: Generate Kaplan-Meier Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  donor  time  survival_probability  failure_probability\n",
      "0                 Donor     5              0.996751             0.003249\n",
      "1                 Donor    12              0.988017             0.011983\n",
      "2                 Donor    15              0.983427             0.016573\n",
      "3  NotSoHealthyNondonor     5              0.855844             0.144156\n",
      "4  NotSoHealthyNondonor    12              0.653661             0.346339\n",
      "5  NotSoHealthyNondonor    15              0.575531             0.424469\n",
      "6       HealthyNondonor     5              0.981093             0.018907\n",
      "7       HealthyNondonor    12              0.934715             0.065285\n",
      "8       HealthyNondonor    15              0.912715             0.087285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Assuming 'data' is already the DataFrame loaded previously\n",
    "\n",
    "# Set the event indicator based on 'Died'\n",
    "data['event'] = (data['rSMGJcEdF_d'] == 'Died').astype(int)\n",
    "\n",
    "# Ensure date columns are in datetime format\n",
    "data['rSMGJcEdF_tT'] = pd.to_datetime(data['rSMGJcEdF_tT'], errors='coerce')\n",
    "data['rSMGJcEdF_t0'] = pd.to_datetime(data['rSMGJcEdF_t0'], errors='coerce')\n",
    "data['entry'] = data['rSMGJcEdF_t0']  # Use _t0 as entry\n",
    "\n",
    "# Calculate the duration from origin to the event or censoring in years\n",
    "data['duration'] = (data['rSMGJcEdF_tT'] - data['rSMGJcEdF_t0']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    "\n",
    "# Calculate the entry duration\n",
    "data['entry_duration'] = (data['entry'] - data['rSMGJcEdF_t0']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
    "data['entry_duration'] = data['entry_duration'].fillna(0)  # Ensure non-donor entries are set to 0\n",
    "\n",
    "# Ensure all durations are non-negative and valid\n",
    "data = data[(data['duration'] >= 0) & (data['entry_duration'] >= 0)]\n",
    "\n",
    "# Initialize the KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# Time points at which we want to extract survival probabilities\n",
    "time_points = [5, 12, 15]\n",
    "\n",
    "# Dictionary to hold the results\n",
    "results = []\n",
    "\n",
    "# Fit the model for each donor type and extract the survival probabilities\n",
    "for donor in data['donor'].unique():\n",
    "    kmf.fit(durations=data[data['donor'] == donor]['duration'],\n",
    "            event_observed=data[data['donor'] == donor]['event'],\n",
    "            entry=data[data['donor'] == donor]['entry_duration'],\n",
    "            label=donor)\n",
    "    \n",
    "    for time in time_points:\n",
    "        survival_prob = kmf.survival_function_at_times(time).values[0]\n",
    "        results.append({\n",
    "            'donor': donor,\n",
    "            'time': time,\n",
    "            'survival_probability': survival_prob,\n",
    "            'failure_probability': 1 - survival_prob\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('km_results.csv', index=False)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the donor results match [Segev, JAMA, 2010](https://abikesa.github.io/flow/_downloads/57876abeb3d25f47b41ed9b178f3d2c7/jamascript-m.pdf) p. 961. The nondonors here are unmatched and so do not yield the same estimates from this paper\n",
    "\n",
    "A webApp is quick way to approximate these findings using the base-case of the \"typical\" donor as per Table 1, also on page 961. Namely, 40yo white female with some college education, BMI=28, SBP=120, no hypertension, no history of smoking cigarettes, creatinine 0.9 mg/dL, and eGFR 100 mL/min \n",
    "\n",
    "### Block 8: Summarize Failure Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block 9: Kaplan-Meier Survival Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Block 11: Save Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Block 12: Cox Proportional Hazards Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant columns: ['_st', '_t0', 'entry_duration']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is already the DataFrame loaded previously\n",
    "\n",
    "# Check for constant variables\n",
    "constant_columns = [col for col in data.columns if data[col].nunique() <= 1]\n",
    "print(\"Constant columns:\", constant_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant columns removed: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# Ensure 'donor' is a categorical variable\n",
    "data['donor'] = data['donor'].astype('category')\n",
    "\n",
    "# Select necessary columns\n",
    "data = data[['duration', 'event', 'donor']]\n",
    "\n",
    "# Remove constant columns if any\n",
    "constant_columns = [col for col in data.columns if data[col].nunique() <= 1]\n",
    "data = data.drop(columns=constant_columns)\n",
    "\n",
    "print(\"Constant columns removed:\", constant_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>donor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.859001</td>\n",
       "      <td>0</td>\n",
       "      <td>Donor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.409993</td>\n",
       "      <td>0</td>\n",
       "      <td>Donor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.752909</td>\n",
       "      <td>0</td>\n",
       "      <td>Donor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.273785</td>\n",
       "      <td>0</td>\n",
       "      <td>Donor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.398357</td>\n",
       "      <td>0</td>\n",
       "      <td>Donor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    duration  event  donor\n",
       "0  13.859001      0  Donor\n",
       "1   9.409993      0  Donor\n",
       "2   8.752909      0  Donor\n",
       "3   8.273785      0  Donor\n",
       "4  14.398357      0  Donor"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pers_id   don_id don_yearcat  don_age don_agecat don_female don_race_ethn  \\\n",
      "0  5005738  AAEN566   1998-2001       44      40-49     Female   White/Other   \n",
      "1  4973528   ZIF796   2002-2005       47      40-49     Female   White/Other   \n",
      "2  4961779   ZFV631   2002-2005       38      18-39     Female      Hispanic   \n",
      "3  4961603   ZFN933   2006-2009       38      18-39       Male      Hispanic   \n",
      "4  4949318   ZCU948   1998-2001       18      18-39     Female   White/Other   \n",
      "\n",
      "    don_educat don_hyperten  don_smoke  ...  rSMGJcEdF_t rSMGJcEdF_x  age_t0  \\\n",
      "0          NaN   No History     Smoker  ...    11.192334         rSM      44   \n",
      "1  <HighSchool          NaN  NoHistory  ...     6.743327         rSM      47   \n",
      "2  <HighSchool   No History  NoHistory  ...     6.086242         rSM      38   \n",
      "3  <HighSchool   No History  NoHistory  ...     5.607119         rSM      38   \n",
      "4          NaN   No History  NoHistory  ...    11.731690         rSM      18   \n",
      "\n",
      "      age_tT  female race  _st _d         _t _t0  \n",
      "0  55.192333       1  1.0    1  0  11.192334   0  \n",
      "1  53.743330       1  1.0    1  0   6.743327   0  \n",
      "2  44.086243       1  3.0    1  0   6.086242   0  \n",
      "3  43.607117       0  3.0    1  0   5.607119   0  \n",
      "4  29.731690       1  1.0    1  0  11.731690   0  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "Index(['pers_id', 'don_id', 'don_yearcat', 'don_age', 'don_agecat',\n",
      "       'don_female', 'don_race_ethn', 'don_educat', 'don_hyperten',\n",
      "       'don_smoke', 'don_bmi', 'don_bmicat', 'don_bp_preop_syst', 'don_sbpcat',\n",
      "       'don_bp_preop_diast', 'don_dbpcat', 'don_egfr', 'don_egfrcat', 'creat',\n",
      "       'don_related', 'n2e_d', 'n2e_t', 'donor', 'healthy', 'acr', 'case',\n",
      "       'id', 'rSMGJcEdF_d', 'rSMGJcEdF_t0', 'rSMGJcEdF_tT', 'rSMGJcEdF_t',\n",
      "       'rSMGJcEdF_x', 'age_t0', 'age_tT', 'female', 'race', '_st', '_d', '_t',\n",
      "       '_t0'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z3/nwmg00j178vfczmb9nk9487h0000gn/T/ipykernel_44009/1876344631.py:5: DtypeWarning: Columns (1,2,19,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = '~/documents/melody/local/esrdRisk_t02tT.csv'  # Adjust the file path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows and the column names\n",
    "print(data.head())\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients and Hazard Ratios Relative to Baseline (Donor):\n",
      "                                   coef  exp(coef)  exp(coef) lower 95%  \\\n",
      "HealthyNondonor vs Donor      -0.286770   0.750684             0.447060   \n",
      "NotSoHealthyNondonor vs Donor  2.359067  10.581077             8.187331   \n",
      "\n",
      "                               exp(coef) upper 95%  \n",
      "HealthyNondonor vs Donor                  1.260518  \n",
      "NotSoHealthyNondonor vs Donor            13.674688  \n",
      "\n",
      "Hazard Ratios Relative to Baseline (Donor):\n",
      "                               Hazard Ratio  Lower 95% CI  Upper 95% CI\n",
      "HealthyNondonor vs Donor           0.750684      0.447060      1.260518\n",
      "NotSoHealthyNondonor vs Donor     10.581077      8.187331     13.674688\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# Assuming 'data' is already the DataFrame loaded previously and necessary preprocessing is done\n",
    "\n",
    "# Ensure 'donor' is a categorical variable\n",
    "data['donor'] = data['donor'].astype('category')\n",
    "\n",
    "# Fit a Cox proportional hazards model\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(data, duration_col='duration', event_col='event', formula=\"C(donor)\")\n",
    "\n",
    "# Extract the summary and relevant coefficients\n",
    "summary = cph.summary\n",
    "\n",
    "# Filter only relevant columns\n",
    "coefficients = summary.loc[:, ['coef', 'exp(coef)', 'exp(coef) lower 95%', 'exp(coef) upper 95%']]\n",
    "\n",
    "# Rename the rows for clarity\n",
    "coefficients.index = ['HealthyNondonor vs Donor', 'NotSoHealthyNondonor vs Donor']\n",
    "\n",
    "# Display the simplified results\n",
    "print(\"Coefficients and Hazard Ratios Relative to Baseline (Donor):\")\n",
    "print(coefficients)\n",
    "\n",
    "# Compute hazard ratios\n",
    "hazard_ratios = coefficients[['exp(coef)', 'exp(coef) lower 95%', 'exp(coef) upper 95%']]\n",
    "hazard_ratios.columns = ['Hazard Ratio', 'Lower 95% CI', 'Upper 95% CI']\n",
    "\n",
    "print(\"\\nHazard Ratios Relative to Baseline (Donor):\")\n",
    "print(hazard_ratios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Block 13: Save Baseline Survival and Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```stata\n",
    "// Define matrix 'b' with model coefficients\n",
    "matrix define b = e(b)\n",
    "\n",
    "// Keep baseline survival estimates\n",
    "keep s0 _t \n",
    "\n",
    "// Sort and list baseline survival estimates\n",
    "sort _t s0\n",
    "list in 1/10\n",
    "\n",
    "// Save baseline survival estimates\n",
    "save ${dir}/s0.dta, replace\n",
    "export delimited using ${dir}/s0.csv, replace\n",
    "\n",
    "// Save model coefficients\n",
    "matrix beta = e(b)\n",
    "svmat beta\n",
    "keep beta*\n",
    "drop if missing(beta1)\n",
    "list \n",
    "save ${dir}/b.dta, replace\n",
    "export delimited using ${dir}/b.csv, replace\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}